{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a4cb1bc",
   "metadata": {
    "id": "6a4cb1bc"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstats\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m skew, kurtosis\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_curve\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "import keras_tuner as kt # used for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556e99ba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "id": "556e99ba",
    "outputId": "644c9b72-f60e-4050-f0f4-8ff765fc6181"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
    "\n",
    "# Printing first 5 records of the dataset\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40ac370",
   "metadata": {
    "id": "e40ac370"
   },
   "source": [
    "## Dealing with Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13d7c7a",
   "metadata": {
    "id": "f13d7c7a"
   },
   "source": [
    "### For Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb3e9f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 742
    },
    "id": "9fb3e9f5",
    "outputId": "071da5e7-108e-40e5-de85-0db51c93a46b"
   },
   "outputs": [],
   "source": [
    "# to check for which column has null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c549db4d",
   "metadata": {
    "id": "c549db4d"
   },
   "source": [
    "We can see that the dataset is freshed and contains no null values.\\\n",
    "Still sometimes a column may contain empty values (as spaces or NaNs). So we can check those and if any deal with them.\n",
    "TotalCharge column as such empty string and that is why it is shown as object type rather than float64. So we can force TotalCharges to be converted to numeric data and then etting errors='coerce', which will convert any non-numeric entries to NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb68405",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bdb68405",
    "outputId": "6899cb8d-46a3-494e-c3de-27ac5388873b"
   },
   "outputs": [],
   "source": [
    "# Convert 'TotalCharges' to numeric, coercing any errors to NaN\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895d6420",
   "metadata": {
    "id": "895d6420"
   },
   "source": [
    "So we can see there is 11 null values for TotalCharges column. Here we deal them by applying KNN Imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270811a8",
   "metadata": {
    "id": "270811a8"
   },
   "outputs": [],
   "source": [
    "# Select columns with numeric data types only\n",
    "num_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "# Select columns with categorical data types without target column Churn\n",
    "cat_cols = df.select_dtypes(include=['object', 'category']).columns.drop(\"Churn\").tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db078806",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "db078806",
    "outputId": "a54e4078-be7b-4791-e0c1-65dedd5ce98a"
   },
   "outputs": [],
   "source": [
    "# plot histograms for numerical features\n",
    "df[num_cols].hist(figsize=(15, 12), bins=30, edgecolor='black')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7891fc",
   "metadata": {
    "id": "2e7891fc"
   },
   "source": [
    "We can see above histogram that SeniorCitizen has only two values. Therefore, we will leave this feature unchanged in the dataset. It will be treated similarly to other categorical or binary indicator features. Moreover, other features are skewed. So we can perform transformation according to skewness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd96d2e5",
   "metadata": {
    "id": "fd96d2e5"
   },
   "outputs": [],
   "source": [
    "# we remove \"SeniorCitizen\" column from numerical features\n",
    "num_cols = [n for n in num_cols if n != \"SeniorCitizen\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13383936",
   "metadata": {
    "id": "13383936"
   },
   "source": [
    "### calculate skewness for the numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631768fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "631768fa",
    "outputId": "3ac5f755-bc2d-4d5e-c12d-6a492b44327e"
   },
   "outputs": [],
   "source": [
    "# check for skewed data\n",
    "# Calculate skewness for each numerical column using skew and kurtosis\n",
    "skewness = df[num_cols].apply(lambda x: skew(x.dropna()))\n",
    "\n",
    "kurt = df[num_cols].apply(lambda x: kurtosis(x.dropna()))\n",
    "\n",
    "# Combine skewness and kurtosis in a DataFrame\n",
    "num_cols_df = pd.DataFrame({'Skewness': skewness, 'Kurtosis': kurt})\n",
    "print(num_cols_df.sort_values(by = ['Skewness', 'Kurtosis'], ascending=[True, True]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84b1288",
   "metadata": {
    "id": "c84b1288"
   },
   "source": [
    "1. MonthlyCharges\\\n",
    "Skewness: -0.220 (slightly negatively skewed)\\\n",
    "Kurtosis: -1.257 (platykurtic, meaning it has a flat distribution compared to a normal distribution)\\\n",
    "Interpretation: The distribution of MonthlyCharges is close to symmetric (skewness is near zero) and has lower peak (flatness) than a normal distribution.\n",
    "\n",
    "2. tenure\\\n",
    "Skewness: 0.239 (slightly positively skewed)\\\n",
    "Kurtosis: -1.387 (also platykurtic, or flatter than a normal distribution)\\\n",
    "Interpretation: Like MonthlyCharges, tenure has a near-normal distribution. It has a very slight positive skew and is also somewhat flat, with fewer extreme values.\n",
    "\n",
    "Action: For both the features, no transformation is needed here, as the skewness is minimal.\n",
    "\n",
    "3. TotalCharges\\\n",
    "Skewness: 0.961 (moderate positive skew)\\\n",
    "Kurtosis: -0.232 (slightly platykurtic but close to normal)\\\n",
    "Interpretation: TotalCharges has a moderate positive skew, meaning the distribution is pulled towards higher values. This skewness could potentially affect models sensitive to outliers or skewed data.\\\n",
    "\\\n",
    "Action: Since there’s moderate positive skewness, we can apply a transformation to normalize it. A logarithmic transformation (log1p) can help reduce the skew."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157edcac",
   "metadata": {
    "id": "157edcac"
   },
   "source": [
    "### Check for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d582fe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "41d582fe",
    "outputId": "a6f5c535-39c8-4092-80c4-d106c1868202"
   },
   "outputs": [],
   "source": [
    "# Visualization by Boxplot\n",
    "fig, axes = plt.subplots(len(num_cols), 1, figsize=(8, 12))\n",
    "\n",
    "# Loop through each numerical column and plot both histogram and boxplot\n",
    "# Plot each feature in a separate subplot\n",
    "for i, cols in enumerate(num_cols):\n",
    "    sns.boxplot(data=df[cols], ax=axes[i])\n",
    "    axes[i].set_title(f'Box Plot for Scaled {cols}', fontsize=14)\n",
    "\n",
    "# Adjust layout for better readability\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8dbe1a",
   "metadata": {
    "id": "ae8dbe1a"
   },
   "source": [
    "We can see that there is no outliers for the numerical features. SO we don't need to deal with outliers explicitely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19374135",
   "metadata": {
    "id": "19374135"
   },
   "source": [
    "### Perform Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6986b65a",
   "metadata": {
    "id": "6986b65a"
   },
   "source": [
    "We perform here a pipeline for dealing with missing value of the numerical features, transformation and scalling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1a0cb0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1f1a0cb0",
    "outputId": "623a1114-77a6-4c92-caf2-4de0637aba34"
   },
   "outputs": [],
   "source": [
    "# Define feature groups\n",
    "num_col_skewed = [\"TotalCharges\"]\n",
    "num_col_no_skewed = [col for col in num_cols if col not in num_col_skewed]\n",
    "\n",
    "print(num_col_skewed, num_col_no_skewed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43241791",
   "metadata": {
    "id": "43241791"
   },
   "outputs": [],
   "source": [
    "# Transformer for unskewed numerical features, we perform here only scaling as these features contains no nul values\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()) # Scaling\n",
    "])\n",
    "\n",
    "# Transformer for skewed numerical features\n",
    "num_transformer_skewed = Pipeline(steps=[\n",
    "    ('log_transform', FunctionTransformer(np.log1p, validate=False)),  # Apply log transformation\n",
    "    ('imputer', KNNImputer(n_neighbors=3)),                            # Apply KNN imputation\n",
    "    ('scaler', StandardScaler())                                       # Scaling\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49626d43",
   "metadata": {
    "id": "49626d43"
   },
   "source": [
    "## Categorical Features Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fae19a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "id": "06fae19a",
    "outputId": "0bdcb1bb-43f4-4abf-ca4e-deba7f83e5ad"
   },
   "outputs": [],
   "source": [
    "df[cat_cols].nunique() == len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff245020",
   "metadata": {
    "id": "ff245020"
   },
   "source": [
    "We can see that for customerID column all the values are unique. So, it is best to drop the customerID column.Because, this feature functions purely as an identifier and does not hold any intrinsic predictive value about the target variable.\\\n",
    "But later in future work for Feature Engineering if it is needed we will consider it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ff9d61",
   "metadata": {
    "id": "29ff9d61"
   },
   "outputs": [],
   "source": [
    "# we drop the column customerID\n",
    "df.drop(columns = [\"customerID\"], inplace=True)\n",
    "cat_cols = [c for c in cat_cols if c != \"customerID\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a8574b",
   "metadata": {
    "id": "9a9bd569"
   },
   "source": [
    "We visualize here the target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642909ef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "id": "642909ef",
    "outputId": "b584a55e-32dc-4228-ec36-caaea4ce978c"
   },
   "outputs": [],
   "source": [
    "sns.countplot(data=df, x=\"Churn\", palette='Set2')\n",
    "plt.title(\"Target Feature (Churn)\") # print feature name along with the percantage of missing values in the feature\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7e659c",
   "metadata": {
    "id": "8b7e659c"
   },
   "source": [
    "We can easily notice that in the target feature non-churners constitute the majority class. As a result, dataset is imbalance. Later, we will deal with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d771ea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "77d771ea",
    "outputId": "3af5975b-da3f-4dfd-dfad-d4f8920aaf7a"
   },
   "outputs": [],
   "source": [
    "# Bar Plot, the distribution of a categorical variable\n",
    "# Shows the frequency of each category in a single categorical feature.\n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "for i, column in enumerate(cat_cols, 1):\n",
    "    plt.subplot(4, 5, i)  # Adjust subplot layout as per number of features\n",
    "    sns.countplot(data=df, x=column, palette='Set2')\n",
    "    plt.title(column) # print feature name along with the percantage of missing values in the feature\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593b0063",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 898
    },
    "id": "593b0063",
    "outputId": "1394ef04-f5e0-4582-c9b4-849131b2d257"
   },
   "outputs": [],
   "source": [
    "# Stacked Bar Plot with Target Variable\n",
    "# Shows how each category relates to the target variable, such as the proportion of churned vs. non-churned customers within each category.\n",
    "plt.figure(figsize=(15, 12))\n",
    "for i, column in enumerate(cat_cols, 1):\n",
    "    plt.subplot(4, 5, i)  # Adjust subplot layout as per number of features\n",
    "    sns.countplot(data=df, x=column, hue='Churn')\n",
    "    plt.title(column) # print feature name along with the percantage of missing values in the feature\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31783348",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "31783348",
    "outputId": "b879d3a8-ad4f-4346-accf-00bbce971a5e"
   },
   "outputs": [],
   "source": [
    "# Heatmap of Categorical Features with Target\n",
    "# Shows correlations between multiple categorical features and the target.\n",
    "\n",
    "# Create a crosstab to visualize the relationship between 'Contract' and 'InternetService' with 'Churn'\n",
    "heatmap_df = pd.crosstab(df['InternetService'], df['Contract'], normalize=True)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(heatmap_df, annot=True, fmt=\".2f\", cmap=\"Blues\")\n",
    "plt.title('Contract vs Internet Service Proportions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b4d034",
   "metadata": {
    "id": "60b4d034"
   },
   "source": [
    "## Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2250007e",
   "metadata": {
    "id": "2250007e"
   },
   "source": [
    "For columns with two categories we will use label encoding (e.g., 0 for Male, 1 for Female).\\\n",
    "For columns with more than two categories, we will use one-hot encoding.\\\n",
    "For columns with high cardinality, we will use Binary Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dac4c0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "id": "a8dac4c0",
    "outputId": "ad064c87-27a1-4863-8f98-5d91a82df8a6"
   },
   "outputs": [],
   "source": [
    "df[cat_cols].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d6bcfa",
   "metadata": {
    "id": "69d6bcfa"
   },
   "source": [
    "Features for 2 unique values we will use label encoding and for others one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2201dd09",
   "metadata": {
    "id": "2201dd09"
   },
   "outputs": [],
   "source": [
    "# high cardinality, nominal and binary variables in the datasets\n",
    "binary_cat = [] # define binary categories in a list for applying label encoding\n",
    "nominal_cat = [] # define nominal categories in a list for applying one-hot encoding\n",
    "\n",
    "for col in cat_cols:\n",
    "    unique_values = df[col].nunique()\n",
    "\n",
    "    # Decide on encoding based on number of unique values and type\n",
    "    if unique_values == 2:\n",
    "        binary_cat.append(col)\n",
    "    else:\n",
    "        nominal_cat.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f1cdc4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "38f1cdc4",
    "outputId": "027d3ded-37b1-43de-d93c-d5ca95af1405"
   },
   "outputs": [],
   "source": [
    "print(binary_cat)\n",
    "print(nominal_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32fadbf",
   "metadata": {
    "id": "c32fadbf"
   },
   "source": [
    "### Perform Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c6abee",
   "metadata": {
    "id": "a3c6abee"
   },
   "source": [
    "Label Encoding: Converts binary categorical columns (Yes/No, Male/Female) to 0 and 1 values.\\\n",
    "One-Hot Encoding for Multi-Class Categorical Features: Converts categorical columns with multiple categories into binary dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18409dbf",
   "metadata": {
    "id": "18409dbf"
   },
   "outputs": [],
   "source": [
    "# Binary categorical transformer using LabelEncoder\n",
    "'''Since LabelEncoder doesn’t support ColumnTransformer directly,\n",
    "we’ll wrap it in a FunctionTransformer to apply it only to the binary categorical columns.'''\n",
    "def label_encode_binary(df):\n",
    "    le = LabelEncoder()\n",
    "    return df.apply(lambda x: le.fit_transform(x))\n",
    "\n",
    "# Binary-class categorical transformer\n",
    "binary_transformer = Pipeline(steps=[\n",
    "    ('label_encoder', FunctionTransformer(label_encode_binary))\n",
    "])\n",
    "\n",
    "# Multi-class categorical transformer: One-Hot Encoding\n",
    "nominal_transformer = Pipeline(steps=[\n",
    "    ('one_hot_encoder', OneHotEncoder(drop='first')) # handle_unknown='ignore'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29535ff",
   "metadata": {
    "id": "b29535ff"
   },
   "source": [
    "## Combine transformers in a ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ff9209",
   "metadata": {
    "id": "36ff9209"
   },
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num_col_no_skewed', num_transformer, num_col_no_skewed), # # Numerical features for no skewed values\n",
    "        ('num_col_skewed', num_transformer_skewed, num_col_skewed), # Numerical features for skewed values\n",
    "        ('binary_encoding', binary_transformer, binary_cat), # LabelEncoder for binary categorical features\n",
    "        ('nominal_encoding', nominal_transformer, nominal_cat) # OneHotEncoder for nominal categorical features\n",
    "    ],\n",
    "    remainder='passthrough'  # Keep the other columns (if any) as is\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb29fde3",
   "metadata": {
    "id": "cb29fde3"
   },
   "source": [
    "## Splitting the Dataset and Handling imbalanced data (Resampling methods+Class Weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c589719",
   "metadata": {
    "id": "0c589719"
   },
   "source": [
    "### Handling Imbalance data\n",
    "Handling imbalanced data is indeed a crucial step in classification tasks like churn prediction, where one class (e.g., customers who churn) may be significantly smaller than the other.\n",
    "\n",
    "We use following techniques to deal with that:\\\n",
    "1. Resampling Techniques (SMOTE)\n",
    "2. Using Class Weights\n",
    "\n",
    "SMOTE is applied after preprocessing but before model training, creating a balanced training set.\n",
    "\n",
    "In models like logistic regression, decision trees, SVM and random forests, we set set class_weight='balanced', which assigns weights inversely proportional to class frequencies. This ensures the model to handle the imbalance by giving more weight to the minority class.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a387d32e",
   "metadata": {
    "id": "a387d32e"
   },
   "outputs": [],
   "source": [
    "# Separate target and features\n",
    "X = df.drop(\"Churn\", axis=1)\n",
    "\n",
    "# Encode the target column separately\n",
    "# Convert target to binary values\n",
    "y = df['Churn'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the training data\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_preprocessed, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f268cc38",
   "metadata": {
    "id": "f268cc38"
   },
   "source": [
    "## Training, Testing, Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c612e5fb",
   "metadata": {
    "id": "c612e5fb"
   },
   "outputs": [],
   "source": [
    "# Define models to compare\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(class_weight='balanced'),\n",
    "    'Decision Tree': DecisionTreeClassifier(class_weight='balanced', random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(class_weight='balanced', random_state=42),\n",
    "    'XGBoost': XGBClassifier(eval_metric='logloss', random_state=42),\n",
    "    'SVM': SVC(class_weight='balanced', probability=True, random_state=42),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Naive Bayes': GaussianNB()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe56559",
   "metadata": {
    "id": "4fe56559",
    "outputId": "71b46970-e7c7-4742-a80a-9369d77feb49"
   },
   "outputs": [],
   "source": [
    "# predicting, testing and evaluation\n",
    "for model_name, model in models.items():\n",
    "\n",
    "    # Train the model (fit the entire pipeline)\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    # Make predictions using the final estimator on the transformed test data\n",
    "    y_pred = model.predict(X_test_preprocessed)\n",
    "\n",
    "    print(f\"{model_name} Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de17a04",
   "metadata": {
    "id": "9de17a04"
   },
   "source": [
    "1. Logistic Regression:\\\n",
    "Accuracy: 75%\\\n",
    "Strength: High recall for class 1 (82%), meaning it captures most positives.\\\n",
    "Weakness: Low precision for class 1 (52%), leading to false positives.\\\n",
    "Best for: Detecting positives but may misclassify negatives.\n",
    "\n",
    "2. Decision Tree:\\\n",
    "Accuracy: 74%\\\n",
    "Strength: Balanced performance for class 0.\\\n",
    "Weakness: Struggles with class 1 (low precision: 50%, recall: 55%).\\\n",
    "Best for: Simple, interpretable model but not ideal for imbalanced data.\n",
    "\n",
    "3. Random Forest:\\\n",
    "Accuracy: 79%\\\n",
    "Strength: Strong precision and recall for class 0 (both ~85%). Improved handling of class 1.\\\n",
    "Weakness: Moderate performance for class 1 (precision: 62%, recall: 57%).\\\n",
    "Best for: Overall balanced and reliable; handles imbalance better than simpler models.\n",
    "\n",
    "4. XGBoost:\\\n",
    "Accuracy: 79%\\\n",
    "Strength: Consistent high performance for class 0. Balanced precision and recall for class 1.\\\n",
    "Weakness: Moderate recall for class 1 (59%).\\\n",
    "Best for: Similar to Random Forest; excellent overall performance.\n",
    "\n",
    "5. SVM (Support Vector Machine):\\\n",
    "Accuracy: 77%\\\n",
    "Strength: High recall for class 1 (80%). Good at detecting positives.\\\n",
    "Weakness: Low precision for class 1 (55%), causing false positives.\\\n",
    "Best for: Reducing false negatives but not false positives.\n",
    "\n",
    "6. KNN (K-Nearest Neighbors):\\\n",
    "Accuracy: 70%\\\n",
    "Strength: Good precision for class 0 (88%).\\\n",
    "Weakness: Poor class 1 precision (46%). Struggles with imbalanced data.\\\n",
    "Best for: Simpler datasets; not ideal here.\n",
    "\n",
    "7. Naive Bayes:\\\n",
    "Accuracy: 67%\\\n",
    "Strength: High recall for class 1 (90%), best at capturing true positives.\\\n",
    "Weakness: Very low precision for class 1 (44%), leading to many false positives.\\\n",
    "Best for: Prioritizing recall over precision; not recommended for balanced results.\n",
    "\n",
    "Top Picks:\\\n",
    "Best Balanced Performance: Random Forest or XGBoost.\\\n",
    "If Recall for Class 1 is Critical: Naive Bayes or Logistic Regression (with tuning to improve precision)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd916af5",
   "metadata": {
    "id": "bd916af5"
   },
   "source": [
    "### Ensemble Methods\n",
    "Ensembles can increase performance by leveraging different strengths of models, especially when combined with balanced resampling.\n",
    "\n",
    "We perform here 2 types of ensembles.\n",
    "1. Voting Classifier:\n",
    "    The Voting Classifier aggregates the predictions of multiple models by voting. There are two main types:\n",
    "    \n",
    "    Hard Voting: Each model makes a class prediction (0 or 1), and the final prediction is the class that gets the majority vote.\\\n",
    "    Soft Voting: Each model outputs a probability for each class, and the final prediction is the class with the highest average probability across models.\n",
    "    \n",
    "   Use Case:\\\n",
    "    Simple and quick to implement.\\\n",
    "    Effective when to combine the strengths of multiple models without additional complexity.\n",
    "\n",
    "\n",
    "2. Stacking Classifier:\n",
    "    Stacking combines multiple base models and feeds their predictions into a meta-model (also known as a second-level model).\\\n",
    "    The meta-model learns how to best combine the outputs of the base models to improve overall performance.\n",
    "    \n",
    "    More powerful and flexible than voting but also more complex.\\\n",
    "    Best used when to exploit the specific strengths of different models and combine them in a learned way to enhance predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a652e64c",
   "metadata": {
    "id": "a652e64c",
    "outputId": "ae07c08b-bc04-4704-859a-4ec0313d8603"
   },
   "outputs": [],
   "source": [
    "# Voting Classifier (for both soft and hard voting)\n",
    "for votes in [\"soft\", \"hard\"]:\n",
    "    voting_clf = VotingClassifier(\n",
    "        estimators=list(models.items()),\n",
    "        voting=votes\n",
    "    )\n",
    "    voting_clf.fit(X_train_resampled, y_train_resampled)\n",
    "    y_pred_voting = voting_clf.predict(X_test_preprocessed)\n",
    "\n",
    "    print(f\"Voting Classifier Classification Report ({votes}):\")\n",
    "    print(classification_report(y_test, y_pred_voting))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02f9d52",
   "metadata": {
    "id": "e02f9d52"
   },
   "source": [
    "Evaluation and Insights:\n",
    "\n",
    "1. Voting Classifier (Soft Voting):\\\n",
    "Accuracy: 78%\\\n",
    "Class 0: High precision (0.90) and good recall (0.79).\\\n",
    "Class 1: Moderate precision (0.56) but strong recall (0.75).\\\n",
    "F1-Score: Balanced performance (0.64 for class 1).\\\n",
    "Best for: Situations where capturing true positives is important, as the recall for class 1 is high.\n",
    "\n",
    "\n",
    "2. Voting Classifier (Hard Voting):\\\n",
    "Accuracy: 78%\\\n",
    "Class 0: Similar to soft voting, with high precision (0.90) and good recall (0.79).\\\n",
    "Class 1: Slightly better precision (0.57) and the same recall (0.75).\\\n",
    "F1-Score: Similar overall to soft voting (0.65 for class 1).\\\n",
    "Best for: Robust performance with slightly improved precision for class 1 over soft voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ea0578",
   "metadata": {
    "id": "b7ea0578",
    "outputId": "1379829b-fefe-4b80-e61f-fcaacf4a874d"
   },
   "outputs": [],
   "source": [
    "# Stacking Classifier\n",
    "# we predict here for all model one by one as meta model\n",
    "for k in models.keys():\n",
    "    stacking_clf = StackingClassifier(\n",
    "        estimators=list(models.items()),\n",
    "        final_estimator=models[k],\n",
    "        cv=5\n",
    "    )\n",
    "\n",
    "    stacking_clf.fit(X_train_resampled, y_train_resampled)\n",
    "    y_pred_stacking = stacking_clf.predict(X_test_preprocessed)\n",
    "\n",
    "    print(f\"Stacking Classifier Classification Report ({k}):\")\n",
    "    print(classification_report(y_test, y_pred_stacking))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc128813",
   "metadata": {
    "id": "fc128813"
   },
   "source": [
    "Evaluation and Insights:\n",
    "\n",
    "1. Logistic Regression (Stacking Meta-model):\\\n",
    "Accuracy: 78%\\\n",
    "Class 0: Strong performance (precision: 0.84, recall: 0.87).\\\n",
    "Class 1: Moderate precision (0.60), lower recall (0.53).\\\n",
    "F1-Score: Balanced for class 0 but weaker for class 1.\\\n",
    "Best for: Good overall performance, but weaker at capturing all positives (class 1).\n",
    "\n",
    "2. Decision Tree (Base Model):\\\n",
    "Accuracy: 75%\\\n",
    "Class 0: Good recall (0.85) and precision (0.81).\\\n",
    "Class 1: Lower precision (0.52) and recall (0.46).\\\n",
    "F1-Score: Low for class 1, indicating struggles with minority class.\\\n",
    "Best for: Basic baseline but not suitable for imbalanced data.\n",
    "\n",
    "3. Random Forest (Base Model):\\\n",
    "Accuracy: 79%\\\n",
    "Class 0: High precision (0.83), strong recall (0.89).\\\n",
    "Class 1: Improved precision (0.63) but recall (0.51) is moderate.\\\n",
    "F1-Score: Better handling of class 1 than simpler models.\\\n",
    "Best for: Balanced performance and good for imbalanced data.\n",
    "\n",
    "4. XGBoost (Base Model):\\\n",
    "Accuracy: 78%\\\\\\\n",
    "Class 0: Similar to Random Forest (precision: 0.83, recall: 0.89).\\\\\n",
    "Class 1: Moderate precision (0.62) and recall (0.49).\\\n",
    "F1-Score: Comparable to Random Forest but slightly weaker recall.\\\n",
    "Best for: Robust and reliable overall performance.\n",
    "\\\n",
    "5. Support Vector Machine (SVM, Base Model):\\\n",
    "Accuracy: 79%\\\\\\\n",
    "Class 0: High precision (0.84) and recall (0.88).\\\\\n",
    "Class 1: Precision (0.62) and recall (0.52) are balanced but moderate.\\\n",
    "F1-Score: Similar to XGBoost.\\\n",
    "Best for: Good for handling overall accuracy but not the best at detecting positives.\n",
    "\n",
    "6. KNN (Base Model):\\\n",
    "Accuracy: 79%\\\\\n",
    "Class 0: Strong precision (0.83) and recall (0.88).\\\n",
    "Class 1: Precision (0.61), lower recall (0.51).\\\n",
    "F1-Score: Moderate overall.\\\n",
    "Best for: Simple structure; reliable for class 0 but struggles with class 1.\n",
    "\n",
    "7. Naive Bayes (Base Model):\\\n",
    "Accuracy: 79%\\\n",
    "Class 0: High precision (0.88) but slightly lower recall (0.83).\\\n",
    "Class 1: Improved recall (0.70) and precision (0.59).\\\n",
    "F1-Score: Better recall than other models for class 1.\\\n",
    "Best for: Prioritizing recall in class 1.\n",
    "\n",
    "\n",
    "Top Performers: Random Forest, XGBoost, and SVM consistently achieve high accuracy and good class 0 performance.\\\n",
    "For Class 1 Detection: Naive Bayes shows the best recall for capturing positives.\\\n",
    "Meta-model: Using Logistic Regression in the stacking classifier provides balanced overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af434843",
   "metadata": {
    "id": "af434843"
   },
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb08f32",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5bb08f32",
    "outputId": "8cd8654d-1bfc-4c96-f161-7c349ced2200"
   },
   "outputs": [],
   "source": [
    "# Define a neural network model\n",
    "# L2 regularization to penalize large weights\n",
    "nn_model = Sequential([\n",
    "    Input(shape=(X_train_preprocessed.shape[1],)),\n",
    "    \n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(32, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(16, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nbUd2VPkTD_L",
   "metadata": {
    "id": "nbUd2VPkTD_L"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QZ4eQq01UFSN",
   "metadata": {
    "id": "QZ4eQq01UFSN"
   },
   "outputs": [],
   "source": [
    "# Define the EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss',     # Monitor validation loss\n",
    "                              patience=5,            # Stop after 5 epochs with no improvement\n",
    "                              restore_best_weights=True)  # Restore the best weights\n",
    "\n",
    "# learning rate scheduler to adjust the learning rate dynamically during training\n",
    "#reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tkQORmOqTW5M",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tkQORmOqTW5M",
    "outputId": "e42aa40b-1238-4828-8716-6c91526943a8"
   },
   "outputs": [],
   "source": [
    "hist = nn_model.fit(X_train_preprocessed, y_train,\n",
    "          epochs=100,\n",
    "          batch_size=64,\n",
    "          validation_split=0.2, # validation_data=(X_test_preprocessed, y_test)\n",
    "          callbacks=[early_stopping]) #, reduce_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9f84ce",
   "metadata": {
    "id": "XBuRSVT7Ugwe"
   },
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lK3fAMjlVr6y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lK3fAMjlVr6y",
    "outputId": "5c6ff37f-8e31-4863-866a-cb5c05896106"
   },
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_pred = (nn_model.predict(X_test_preprocessed) > 0.5).astype(\"int\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a84081",
   "metadata": {},
   "source": [
    "Evaluation and Insights:\n",
    "\n",
    "Class-wise Breakdown:\n",
    "\n",
    "Class 0 (Non-Churn/Negative Class):\\\n",
    "Precision: 0.87 (Very good; low false positives)\\\n",
    "Recall: 0.89 (Excellent; captures most true negatives)\\\n",
    "F1-Score: 0.88 (Balanced high precision and recall)\n",
    "\n",
    "Strength: The model performs exceptionally well for class 0, accurately identifying non-churn customers.\n",
    "\n",
    "Class 1 (Churn/Positive Class):\\\n",
    "Precision: 0.66 (Decent; some false positives)\\\n",
    "Recall: 0.62 (Moderate; misses some actual churn cases)\\\n",
    "F1-Score: 0.64 (Balanced but lower than class 0)\\\n",
    "\n",
    "Weakness: The model's performance for class 1 (churn) is moderate. It correctly identifies 62% of churn cases but may miss others.\n",
    "\n",
    "Macro and Weighted Averages:\n",
    "\n",
    "Macro Avg F1-Score: 0.76\\\n",
    "Indicates balanced performance across both classes.\\\n",
    "Weighted Avg F1-Score: 0.81\\\n",
    "Reflects overall accuracy, weighted by class distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a127dc",
   "metadata": {
    "id": "H9-VMehxVv89"
   },
   "source": [
    "### Plotting Accuracy and Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lvQ7yBcUj-9X",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "lvQ7yBcUj-9X",
    "outputId": "752a433d-907a-4f8a-b320-bf835fbc19cc"
   },
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(hist.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(hist.history['loss'], label='Train Loss')\n",
    "plt.plot(hist.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3993559b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "id": "V_Ys1orFktz9",
    "outputId": "f9ac2b41-2742-47ba-cbfc-c2e2c9dd7411"
   },
   "source": [
    "### Analysis of the Updated Learning Curves:\n",
    "\n",
    "1. Accuracy Plot:\n",
    "\n",
    "Training Accuracy Increases: The training accuracy improves consistently, indicating that the model is learning patterns from the training data.\\\n",
    "Validation Accuracy Plateaus: The validation accuracy increases quickly and then plateaus around 80%, suggesting the model is reaching its performance limit.\\\n",
    "Good Generalization: Since the training and validation accuracy curves are close together and have similar trends, the model does not appear to be overfitting significantly.\n",
    "\n",
    "2. Loss Plot:\n",
    "\n",
    "Decreasing Loss: Both the training and validation loss decrease over time, indicating that the model is learning and minimizing the error.\\\n",
    "Similar Loss Curves: The training and validation loss curves are close together, suggesting that the model is not overfitting. If the validation loss was much higher than the training loss, it would indicate overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b2544b",
   "metadata": {
    "id": "o_8Ifds_p4TR"
   },
   "source": [
    "### Plot Precision, Recall, and F1 Score Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XFBsZEW3rGFX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "id": "XFBsZEW3rGFX",
    "outputId": "57a3565c-21b0-47f2-80dc-35671610d2f7"
   },
   "outputs": [],
   "source": [
    "# Calculate precision, recall, and thresholds\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_pred)\n",
    "\n",
    "# Calculate F1 scores for each threshold\n",
    "f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "\n",
    "# Plot Precision-Recall curve and F1 Score curve\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Plot Precision and Recall curve\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(thresholds, precisions[:-1], label=\"Precision\", color=\"blue\")\n",
    "plt.plot(thresholds, recalls[:-1], label=\"Recall\", color=\"green\")\n",
    "plt.title(\"Precision and Recall Curve\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "# Plot F1 Score curve\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(thresholds, f1_scores[:-1], label=\"F1 Score\", color=\"red\")\n",
    "plt.title(\"F1 Score Curve\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2057e408",
   "metadata": {},
   "source": [
    "1. Precision and Recall Curve:\\\n",
    "Blue Line (Precision): Precision decreases as the threshold increases.\\\n",
    "Green Line (Recall): Recall decreases as the threshold increases.\\\n",
    "Threshold Effect:\\\n",
    "Low Thresholds: At lower thresholds (close to 0), recall is high (close to 1), but precision is low. This means the model predicts more positive samples but at the cost of many false positives.\\\n",
    "High Thresholds: At higher thresholds (close to 1), precision is high but recall is low. The model becomes more conservative, predicting fewer positives, but those predictions are more likely to be correct.\n",
    "Trade-off:\\\n",
    "There is always a trade-off between precision and recall. Increasing precision often decreases recall and vice versa.\n",
    "The point where the precision and recall curves intersect could represent a balanced threshold, depending on the application's needs.\n",
    "\n",
    "2. F1 Score Curve:\\\n",
    "Red Line (F1 Score): The F1 score increases linearly with the threshold in this plot.\\\n",
    "F1 Score Behavior:\\\n",
    "The F1 score represents the harmonic mean of precision and recall, balancing the two metrics.\n",
    "Typically, the F1 score should peak at an optimal threshold, but in this plot, it increases steadily, suggesting that the model might need fine-tuning in threshold selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-J0kPy7MsdwE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-J0kPy7MsdwE",
    "outputId": "15b71c60-a306-44ad-d64b-6364808dd1e3"
   },
   "outputs": [],
   "source": [
    "# we can calculate now the optimal threshold from f1-score\n",
    "\n",
    "optimal_idx = np.argmax(f1_scores)  # Index of the max F1 score\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "# Print the optimal threshold\n",
    "print(f\"Optimal Threshold: {optimal_threshold:.4f}\")\n",
    "print(f\"Maximum F1 Score: {f1_scores[optimal_idx]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff6a848",
   "metadata": {
    "id": "XjWhhAZXssuE"
   },
   "source": [
    "### Ensemble Methods:\n",
    "\n",
    "Combine neural networks with other classifiers.\n",
    "\n",
    "Approach: Use Neural Network as a Feature Extractor\n",
    "\n",
    "1. Neural Network extracts high-level features from the data.\n",
    "2. Other classifiers uses these features for final prediction.\n",
    "\n",
    "Steps:\n",
    "1. Train the Neural Network: Train the NN to learn important representations of the data. (It is already done)\n",
    "2. Extract Features: Use the outputs from a hidden layer as new features.\n",
    "3. Train other classifiers: Use these extracted features as inputs to train other classifiers.\n",
    "4. Evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07316820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Features from hidden layers\n",
    "ext_features = Sequential(nn_model.layers[:-1]) # Remove the output layer\n",
    "X_train_ext_features = ext_features.predict(X_train_preprocessed)\n",
    "X_test_ext_features = ext_features.predict(X_test_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9ac141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting, testing and evaluation\n",
    "for model_name, mod in models.items():\n",
    "\n",
    "    # Train the model (fit the entire pipeline)\n",
    "    mod.fit(X_train_ext_features, y_train)\n",
    "\n",
    "    # Make predictions using the final estimator on the transformed test data\n",
    "    y_pred_ext_features = mod.predict(X_test_ext_features)\n",
    "\n",
    "    print(f\"{model_name} Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred_ext_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34619dd7",
   "metadata": {},
   "source": [
    "Evaluation and Insight:\n",
    "\n",
    "1. Logistic Regression:\\\n",
    "Accuracy: 76%\\\n",
    "Class 0: Precision (0.92), Recall (0.74), F1 (0.82)\\\n",
    "Class 1: Precision (0.53), Recall (0.81), F1 (0.64)\\\n",
    "Strengths: Excellent precision for class 0, high recall for class 1.\\\n",
    "Weaknesses: Struggles with false positives for class 1.\\\n",
    "Best for: Balanced handling of imbalanced data with a focus on capturing positives.\n",
    "\n",
    "2. Decision Tree:\\\n",
    "Accuracy: 74%\\\n",
    "Class 0: Precision (0.82), Recall (0.83), F1 (0.82)\\\n",
    "Class 1: Precision (0.51), Recall (0.49), F1 (0.50\\\n",
    "Strengths: Consistent performance for class 0.\\\n",
    "Weaknesses: Weak recall and precision for class 1.\\\n",
    "Best for: Basic feature extraction check, but not ideal for imbalanced datasets.\n",
    "\n",
    "3. Random Forest:\\\n",
    "Accuracy: 80%\\\n",
    "Class 0: Precision (0.84), Recall (0.90), F1 (0.87)\\\n",
    "Class 1: Precision (0.66), Recall (0.53), F1 (0.59)\\\n",
    "Strengths: High accuracy; strong precision and recall for class 0.\\\n",
    "Weaknesses: Moderate recall for class 1.\\\n",
    "Best for: Reliable overall performance; robust feature handling.\n",
    "\n",
    "4. XGBoost:\\\n",
    "Accuracy: 80%\\\n",
    "Class 0: Precision (0.85), Recall (0.88), F1 (0.86)\\\n",
    "Class 1: Precision (0.63), Recall (0.56), F1 (0.59)\\\n",
    "Strengths: Consistent high accuracy; good handling of class 0.\\\n",
    "Weaknesses: Struggles slightly with class 1 recall.\\\n",
    "Best for: Optimized performance on complex data; requires tuning for minority class.\n",
    "\n",
    "5. Support Vector Machine (SVM):\\\n",
    "Accuracy: 76%\\\n",
    "Class 0: Precision (0.92), Recall (0.74), F1 (0.82)\\\n",
    "Class 1: Precision (0.53), Recall (0.81), F1 (0.64)\\\n",
    "Strengths: High precision and recall balance.\\\n",
    "Weaknesses: Class 1 recall and precision slightly inconsistent.\\\n",
    "Best for: Consistent with Logistic Regression; good for linearly separable features.\n",
    "\n",
    "6. K-Nearest Neighbors (KNN):\\\n",
    "Accuracy: 78%\\\n",
    "Class 0: Precision (0.85), Recall (0.86), F1 (0.85)\\\n",
    "Class 1: Precision (0.59), Recall (0.58), F1 (0.59)\\\n",
    "Strengths: Balanced performance across classes.\\\n",
    "Weaknesses: Sensitive to class imbalance; relies on distance metrics.\\\n",
    "Best for: Simplified models; works well with high-dimensional features.\n",
    "\n",
    "7. Naive Bayes:\\\n",
    "Accuracy: 71%\\\n",
    "Class 0: Precision (0.94), Recall (0.65), F1 (0.77)\\\n",
    "Class 1: Precision (0.48), Recall (0.89), F1 (0.62)\\\n",
    "Strengths: High recall for class 1 (best among all models).\\\n",
    "Weaknesses: High false positives for class 0.\\\n",
    "Best for: Prioritizing minority class recall; suitable when capturing all positives is crucial.\n",
    "\n",
    "Top Performers: Random Forest and XGBoost provide the highest accuracy with robust handling of extracted features.\\\n",
    "Class 1 Focus: Naive Bayes excels in capturing positive cases (high recall).\\\n",
    "Balanced Choice: Logistic Regression and SVM maintain a good balance between precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b8de82",
   "metadata": {},
   "source": [
    "### Stacking Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568236d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in models.keys():\n",
    "    # Train Base Models and Combine their Predictions with NN Predictions\n",
    "    stacking_clf_nn = StackingClassifier(\n",
    "                estimators=list(models.items()),\n",
    "                final_estimator=models[k],\n",
    "                cv=5\n",
    "    )\n",
    "\n",
    "    # Fit Base Classifiers and Meta-Classifier with resampled datasets\n",
    "    stacking_clf_nn.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    # Get Base Model Predictions for Meta-Classifier for orginal preprocessed datasets\n",
    "    y_train_pred_stacking_nn = stacking_clf_nn.predict(X_train_preprocessed)\n",
    "    y_test_pred_stacking_nn = stacking_clf_nn.predict(X_test_preprocessed)\n",
    "\n",
    "    # Combine Base and NN Predictions for Meta-Training\n",
    "    stacked_train_preds = np.column_stack((y_train_pred_stacking_nn, X_train_ext_features))\n",
    "    stacked_test_preds = np.column_stack((y_test_pred_stacking_nn, X_test_ext_features))\n",
    "\n",
    "    # Train Final Meta-Classifier on Combined Predictions\n",
    "    meta_model = models[k]\n",
    "    meta_model.fit(stacked_train_preds, y_train)\n",
    "\n",
    "    # Final Prediction on Test Data\n",
    "    final_preds = meta_model.predict(stacked_test_preds)\n",
    "\n",
    "    # Evaluate the Model\n",
    "    print(f\"Stacking Classifier Classification Report ({k}):\")\n",
    "    print(classification_report(y_test, final_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8ef699",
   "metadata": {},
   "source": [
    "Evaluation and Insight:\n",
    "\n",
    "1. Logistic Regression (Stacked):\\\n",
    "Accuracy: 78%\\\n",
    "Class 0: Precision (0.84), Recall (0.87), F1 (0.86)\\\n",
    "Class 1: Precision (0.60), Recall (0.53), F1 (0.56)\\\n",
    "Strengths: Strong recall for class 0.\\\n",
    "Weaknesses: Recall and precision for class 1 could be better.\\\n",
    "Best for: Balanced accuracy with consistent performance for class 0.\n",
    "\n",
    "2. Decision Tree (Stacked):\n",
    "Accuracy: 75%\\\n",
    "Class 0: Precision (0.82), Recall (0.84), F1 (0.83)\\\n",
    "Class 1: Precision (0.53), Recall (0.49), F1 (0.51)\\\n",
    "Strengths: Consistent precision and recall for class 0.\\\n",
    "Weaknesses: Struggles with class 1 detection.\\\n",
    "Best for: Simple, interpretable models but limited class 1 handling.\n",
    "\n",
    "3. Random Forest (Stacked):\\\n",
    "Accuracy: 79%\\\n",
    "Class 0: Precision (0.83), Recall (0.89), F1 (0.86)\\\n",
    "Class 1: Precision (0.63), Recall (0.50), F1 (0.55)\\\n",
    "Strengths: Strong class 0 performance.\\\n",
    "Weaknesses: Moderate class 1 recall.\\\n",
    "Best for: Reliable overall performance; works well for large feature sets.\n",
    "\n",
    "4. XGBoost (Stacked):\\\n",
    "Accuracy: 79%\\\n",
    "Class 0: Precision (0.83), Recall (0.89), F1 (0.86)\\\n",
    "Class 1: Precision (0.62), Recall (0.50), F1 (0.55)\\\n",
    "Strengths: Consistent accuracy and good feature learning.\\\n",
    "Weaknesses: Moderate performance for minority class recall.\\\n",
    "Best for: Handling complex patterns; suitable for further tuning.\n",
    "\n",
    "5. Support Vector Machine (SVM) (Stacked):\\\n",
    "Accuracy: 79%\\\n",
    "Class 0: Precision (0.84), Recall (0.88), F1 (0.86)\\\n",
    "Class 1: Precision (0.62), Recall (0.52), F1 (0.57)\\\n",
    "Strengths: Balanced accuracy; good handling of class 0.\\\n",
    "Weaknesses: Class 1 recall could improve.\\\n",
    "Best for: Consistent class separation; performs well with high-dimensional data.\n",
    "\n",
    "6. K-Nearest Neighbors (KNN) (Stacked):\\\n",
    "Accuracy: 79%\\\n",
    "Class 0: Precision (0.83), Recall (0.89), F1 (0.86)\\\n",
    "Class 1: Precision (0.62), Recall (0.50), F1 (0.56)\\\n",
    "Strengths: Strong for majority class detection.\\\n",
    "Weaknesses: Sensitive to imbalanced data.\\\n",
    "Best for: Simple datasets with fewer features; performs well with sufficient data points.\n",
    "\n",
    "7. Naive Bayes (Stacked):\\\n",
    "Accuracy: 74%\\\n",
    "Class 0: Precision (0.92), Recall (0.70), F1 (0.80)\\\n",
    "Class 1: Precision (0.50), Recall (0.84), F1 (0.63)\\\n",
    "Strengths: High recall for class 1.\\\n",
    "Weaknesses: Lower precision for class 1; prone to false positives.\\\n",
    "Best for: Prioritizing recall for minority class; good for highly imbalanced data.\n",
    "\n",
    "Top Performers: XGBoost and Random Forest deliver the best accuracy (79%) and class 0 performance.\\\n",
    "Balanced Class Handling: SVM and Logistic Regression perform well across classes, especially with precision and recall balance.\\\n",
    "Minority Class Focus: Naive Bayes captures class 1 well with high recall, valuable when false negatives are costly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c71016e",
   "metadata": {},
   "source": [
    "### Best Model Evaluation\n",
    "\n",
    "Till now, based on the detailed classification reports and metrics:\\\n",
    "Best Overall: Neural Network model, because of it's highest accuracy and balanced class performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114c906b",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning of the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae40e305",
   "metadata": {},
   "source": [
    "We use here Keras Tuner (Random Search or Hyperband)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ad9dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Input Layer\n",
    "    model.add(Input(shape=(X_train_preprocessed.shape[1],)))\n",
    "\n",
    "    # First Hidden Layer\n",
    "    model.add(Dense(\n",
    "        units=hp.Choice('layer1', values=[16, 32, 64, 128]),\n",
    "        activation='relu',\n",
    "        kernel_regularizer=l2(hp.Choice('l2_layer1', values=[0.1, 0.01, 0.001, 0.0001]))\n",
    "    ))\n",
    "    \n",
    "    model.add(Dropout(hp.Float('dropout1', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "    \n",
    "    # Second Hidden Layer\n",
    "    model.add(Dense(\n",
    "        units=hp.Choice('layer2', values=[16, 32, 64, 128]),\n",
    "        activation='relu',\n",
    "        kernel_regularizer=l2(hp.Choice('l2_layer2', values=[0.1, 0.01, 0.001, 0.0001]))\n",
    "    ))\n",
    "\n",
    "    model.add(Dropout(hp.Float('dropout2', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "\n",
    "    # Third Hidden Layer\n",
    "    model.add(Dense(\n",
    "        units=hp.Choice('layer3', values=[16, 32, 64, 128]),\n",
    "        activation='relu',\n",
    "        kernel_regularizer=l2(hp.Choice('l2_layer3', values=[0.1, 0.01, 0.001, 0.0001]))\n",
    "    ))\n",
    "    \n",
    "    model.add(Dropout(hp.Float('dropout3', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "    \n",
    "    # Output Layer\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Binary classification\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=hp.Choice('learning_rate', values=[0.0001, 0.001, 0.01])),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9901ac39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Keras Tuner (Random Search or Hyperband)\n",
    "\"\"\"\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=20,  # Number of models to try\n",
    "    executions_per_trial=2,  # Average results over multiple runs\n",
    "    directory='nn_hyperparameters_rs',\n",
    "    project_name='Telco_customer_churm'\n",
    ")\"\"\"\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=50,\n",
    "    factor=3,\n",
    "    directory='nn_hyperparameters_hb',\n",
    "    project_name='Telco_customer_churm'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93440eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for the best hyperparameters\n",
    "tuner.search(X_train_preprocessed, y_train, epochs=100, validation_split=0.2, batch_size=tuner.oracle.hyperparameters.Choice('batch_size', values=[16, 32, 64]), callbacks=[early_stopping])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters()[0]\n",
    "print(f\"\"\"\n",
    "Optimal Hyperparameters:\n",
    "- Units in Layer 1: {best_hps.get('layer1')}\n",
    "- L2 Regularization in Layer 1: {best_hps.get('l2_layer1')}\n",
    "- Dropout in Layer 1: {best_hps.get('dropout1')}\n",
    "- Units in Layer 2: {best_hps.get('layer2')}\n",
    "- L2 Regularization in Layer 2: {best_hps.get('l2_layer2')}\n",
    "- Dropout in Layer 2: {best_hps.get('dropout2')}\n",
    "- Units in Layer 3: {best_hps.get('layer3')}\n",
    "- L2 Regularization in Layer 3: {best_hps.get('l2_layer3')}\n",
    "- Dropout in Layer 3: {best_hps.get('dropout3')}\n",
    "- Learning Rate: {best_hps.get('learning_rate')}\n",
    "- Batch Size: {best_hps.get('batch_size')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3456639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the best model on the full training data\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "history = best_model.fit(X_train_preprocessed, y_train, epochs=100, validation_split=0.2, batch_size=int(best_hps.get('batch_size')), callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_loss, test_accuracy = best_model.evaluate(X_test_preprocessed, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3edb99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
